<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Defects in Fatigue Fracture Surfaces</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="Report1_files/libs/clipboard/clipboard.min.js"></script>
<script src="Report1_files/libs/quarto-html/quarto.js"></script>
<script src="Report1_files/libs/quarto-html/popper.min.js"></script>
<script src="Report1_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Report1_files/libs/quarto-html/anchor.min.js"></script>
<link href="Report1_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Report1_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Report1_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Report1_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Report1_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Defects in Fatigue Fracture Surfaces</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="defects-in-fatigue-fracture-surfaces" class="level1">
<h1>Defects in Fatigue Fracture Surfaces</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<section id="fatigue" class="level3">
<h3 class="anchored" data-anchor-id="fatigue">Fatigue</h3>
<p>Fatigue is a common failure mechanism for commerical equipment. Fatigue is caused by a stress concentration which causes cracks to nucleate as the surface is loaded and unloaded many time. Cracks cause stress concentration, and the larger the crack the faster the growth, which creates a positive feedback loop. Two common stress concentrators are a rough surface and defects within a sample. <img src="packages/AdvSegLearn/Usage/image36.png" class="img-fluid" alt="Star Guards"></p>
</section>
<section id="eda" class="level3">
<h3 class="anchored" data-anchor-id="eda">EDA</h3>
<p>This is problematic because there is great interest from the Aerospace industry to manufacture low-volume complex parts with Laser Powder Bed Fusion. However, fatigue is a major problem for the Aerospace industry because flight inherintely causes intense cyclic loading, and Laser Powder Bed Fusion is known to cause a variety of defects. In order to investigate this further, Professor Lewandowskiâ€™s lab did a high throughput experiment testing the impact of different processing parameters on the fatigue properties of Ti-6Al-4V in 4 point bending. After fracture, the samples were imaged in an SEM, and, in order to get quantitiative information from these images, were segmented. However, because this is a time consuming process, it can take upwards of 4 hours for a single sample, making use of the entire dataset infeasable. However, with a small subset of segmented images, a machine learning model can be trained and applied to the entire datase. To start, the dataset must be combined and validated. Below are the functions needed.</p>
<p><img src="packages/AdvSegLearn/Usage/image101.png" class="img-fluid" alt="Star Guards"> <img src="packages/AdvSegLearn/Usage/image98.png" class="img-fluid" alt="Star Guards"> ### Sorting Dataset</p>
<pre class="{python}"><code># %% Import
import pandas as pd
import re
import datetime
import cv2
import numpy as np
import math
import os
import PIL
import numpy as np
STITCHED_THRESHOLD = 3000000
UPPER_RED_THRESHOLD = 1000
LOWER_RED_THRESHOLD = 20

check = re.compile(r'''
    ^
    (?:x)?
    (?:\d+)?
    (?:[a-b])?
    [-]?
    (?:Copy\ of\ |Overview|_STD_ETD_|Initiation)?  # Optional prefixes
    [-]?
    [\d]?
    [-]?
    [x]?
    (?:\d+)?
    [-]?
    (EP|NASA|CMU)                                  # Start with EP, NASA, or CMU (case insensitive)
    [-_]?                                          # Optional separator
    (\d+|O\d+)                                     # Number or O followed by number
    [-_]?                                        # Optional separator
    V?
    ([E\d]+|\d+)                                   # Version number
    [-_]?                                          # Optional separator
    (\d+)?                                         # Optional additional number
    (?:_MARKED)?                                   # Optional '_MARKED' suffix
    (.*)?                                          # Any characters in between (greedy by default)
    \.(png|tif|tiff|jpg)$                          # File extension
    ''', re.VERBOSE | re.IGNORECASE)

def log_message(file_path, message):
    # Get the current date and time
    now = datetime.datetime.now()
    timestamp = now.strftime('%Y-%m-%d %H:%M:%S')

    # Create the log entry
    log_entry = f'[{timestamp}] {message}\n'

    # Append the log entry to the file
    with open(file_path, 'a') as file:
        file.write(log_entry)
def m(x):
    try:
        m_f = re.match(r'^([A-Z]+)(\d+)-[V]?(\d+|E\d+)[-]?(\d+)?',x)
    except TypeError:
        return None
    if m_f:
        if(m_f.lastindex==4):
            return m_f.group(1)+m_f.group(2).lstrip('0').lstrip('O')+'-'+m_f.group(3)+'-'+str(int(m_f.group(4)))
        else:
            return m_f.group(1)+m_f.group(2).lstrip('0').lstrip('O')+'-'+m_f.group(3)+'-'+str('1')
    else:
        return None
def name_to_power(name:str, position:int):
    for idx, option in enumerate(process_parameters['Test ID']):
        if(option[2] == name[position]):
            return process_parameters['P (W)'][idx]
def name_to_velocity(name:str,position:int):
    for idx, option in enumerate(process_parameters['Test ID']):
        if(option[2] == name[position]):
            return process_parameters['V (mm/s)'][idx]
def clean_name(input):
    return input.astype(str).str.replace('0','').str.rstrip('.')
def clean_BuildID(input):
    try:
        match = re.match(r'([A-Z]+)(\d+)',input,re.IGNORECASE)
        if match:
            prefix = match.group(1).lstrip('O')
            numeric_part = match.group(2).lstrip('0')
            return prefix + numeric_part
    except TypeError:
        print(input)
#Adds File if Condition(path) return True
def recursive_search(condition,path:str, file_list:list):
    if os.path.isdir(path):
        for path_loop in os.listdir(path):
            recursive_search(condition,os.path.join(path,path_loop),file_list)
    else:
        if(condition(path)):
            file_list.append(path)
    return file_list
#Functions used for Validation
def size(image_path):
    img = cv2.imread(image_path)
    try:
        return img.shape[0] * img.shape[1]
    except AttributeError:
        print('File is corrupted: '+image_path)
        return -1
def size_red(image_path):
   img = cv2.imread(image_path)
   try:
        #Convert the image from BGR to HSV color space
        hsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

        # Define the lower and upper bounds for the red color in HSV space
        lower_red_1 = np.array([0, 50, 50])
        upper_red_1 = np.array([10, 255, 255])
        lower_red_2 = np.array([170, 50, 50])
        upper_red_2 = np.array([180, 255, 255])

        # Create masks for the red color ranges
        mask1 = cv2.inRange(hsv_image, lower_red_1, upper_red_1)
        mask2 = cv2.inRange(hsv_image, lower_red_2, upper_red_2)

        # Combine the masks
        red_mask = mask1 + mask2

        # Count the number of red pixels
        red_pixels = cv2.countNonZero(red_mask)

        return(red_pixels)
   except AttributeError:
       print('File is corrupted: '+image_path)
       return -1
def is_greyscale(image_path):
    img = cv2.imread(image_path)
    if len(img.shape) &lt; 3:
        return True
    if img.shape[2] == 1:
        return True
    # If the image is color, check if all channels are equal
    if np.allclose(img[:, :, 0], img[:, :, 1]) and np.allclose(img[:, :, 1], img[:, :, 2]):
        return True
    return False

def is_binary(path):
    try:
        img = PIL.Image.open(path)
        img = img.convert('L')
        img_data = np.array(img)
        unique_vals = np.unique(img_data)
        if len(unique_vals) == 2 and set(unique_vals) == {0, 255}:
            return True
        else:
            return False
    except PIL.UnidentifiedImageError:
        return False    

def is_8bit(path):
    try:
        img = PIL.Image.open(path)
        img = img.convert('L')
        img_data = np.array(img)
        if img_data.min() &lt; 0 or img_data.max() &gt; 255:
            return False
        else:
            return True
    except PIL.UnidentifiedImageError:
        return False

#Different columns that would be valuable to have
def valid_image(path):
    for i in ['.csv','.hdr','.xlsx']:
        if i in path:
            return False
    if is_8bit(path):
        return True
    else:
        return False
def marked(path):
    if 'marked' in path.lower() and valid_image(path) and not is_greyscale(path):
        return True
    else:
        return False
def initiation(path):
    if ('_001' in path or 'initiation' in path.lower()) and valid_image(path) and size(path)&lt;STITCHED_THRESHOLD:
        return True
    else:
        return False
def stitched(path):
    if ('stitched' in path.lower() or 'composite' in path.lower()) and valid_image(path) and size(path) &gt;STITCHED_THRESHOLD:
        return True
    else:
        return False
def full_surface_marked(path):
    if stitched(path) and (not is_greyscale(path)) and (size_red(path)&gt;UPPER_RED_THRESHOLD):
        return True
    else:
        return False
def initation_marked_stitched(path):
    if stitched(path) and (not is_greyscale(path)) and (LOWER_RED_THRESHOLD&lt;size_red(path)&lt;UPPER_RED_THRESHOLD):
        return True
    else:
        return False
def fatigue(path):
    if 'fatigue' in path.lower() and valid_image(path) and is_binary(path):
        return True
    else:
        return False
def overload(path):
    if 'overload' in path.lower() and valid_image(path) and is_binary(path):
        return True
    else:
        return False
def exclude(input):
    conditions = ['.hdr', '.csv','.info','.xlsx','.info','.pptx','.s0001','.zip','.model']
    for condition in conditions:
        if condition in input: return True
    return False

def check_regex_basename(dict_to_search,search_function, exclude_conditions):
    i=0
    for key in dict_to_search:
        for field in dict_to_search[key]:
            basename = field.split('/')[-1]
            if not search_function(basename) and not exclude(basename):
                print(basename)
                i+=1
        print('Unselected files: '+str(i))
def regex_basename(pattern):
    match = re.search(check,pattern)
    if(match):
        type_func = clean_BuildID(match.group(1)+match.group(2))
        series_func = match.group(3).lstrip("0")
        if match.group(4):
            posit_idx_func = match.group(4).lstrip("0")
        else:
            posit_idx_func = None
        return type_func, series_func,posit_idx_func
    else:
        return None
LOG_FILE = '/home/aml334/CSE_MSE_RXF131/lab-staging/mds3/AdvManu/fractography/combined_df_log.txt'
MESSAGE = 'Added lower threshold for initation_marked_stitched'

manuel_mask_path = '/mnt/vstor/CSE_MSE_RXF131/lab-staging/mds3/keyence-fractography/manuel_mask'
fractography_path = '/mnt/vstor/CSE_MSE_RXF131/staging/mds3/fractography'
csv_dir = "/mnt/vstor/CSE_MSE_RXF131/lab-staging/mds3/AdvManu/fractography/Sample#csvs"
path_list = [fractography_path,manuel_mask_path]
condition_list = [
    valid_image,
    initiation,
    stitched,
    full_surface_marked,
    initation_marked_stitched,
    fatigue,
    overload
]</code></pre>
<p>This was run non-interatively because validation is a time consuming process.</p>
<pre class="{python3}"><code># if __name__=="__main__":
#     # EP04,5,7 + NASA
#     EP04 = pd.read_excel('/mnt/vstor/CSE_MSE_RXF131/staging/mds3/fractography/EP04 (Complete)/EP04 Fractographical Data.xlsx')
#     EP05 = pd.read_excel('/mnt/vstor/CSE_MSE_RXF131/staging/mds3/fractography/EP05/EP05 Fractographical Data_cycles_added.xlsx')
#     EP07 = pd.read_excel('/mnt/vstor/CSE_MSE_RXF131/staging/mds3/fractography/EP07/EP07-Fractographical Data.xlsx')
#     NASA = pd.read_excel('/home/aml334/CSE_MSE_RXF131/staging/mds3/fractography/NASA03/NASA Fractographical Data_Chris-Updated 9_2.xlsx',skiprows=1)
#     output = pd.concat([EP04,EP05,EP07,NASA])
#     output['Sample#'] = output['Sample#'].apply(m)
#     output.insert(0,'Test ID',output['Sample#'] + '-0')
#     del EP04
#     del EP05
#     del EP07
#     del NASA

#     process_parameters = pd.read_csv('/mnt/vstor/CSE_MSE_RXF131/staging/mds3/fractography/variable-process-parameters.csv')

#     output['Load Ratio (R)'] = 0.1
#     output['Scan Power (W)'] = output['Sample#'].apply(lambda row:name_to_power(row,4))
#     output['Scan velocity (mm/s)'] = output['Sample#'].apply(lambda row: name_to_velocity(row,4))
#     output['Retest']=0
#     output.head(3)
#     del name_to_power
#     del name_to_velocity
#     del process_parameters
#     #Brett Spreashsheet
#     Brett_spreadsheet = pd.ExcelFile('/mnt/vstor/CSE_MSE_RXF131/staging/mds3/fractography/4-pt Bend Data Master Spreadsheet_exit_8_27_24.xlsx')
#     excel_df = pd.DataFrame()
#     for worksheet in Brett_spreadsheet.sheet_names:
#         if worksheet not in ['Template','To Test','Retest']:
#             excel_df = pd.concat([excel_df,pd.read_excel(Brett_spreadsheet,worksheet)])
#     del Brett_spreadsheet

#     #Making key

#     excel_df['Sample#'] = excel_df['Build ID'].apply(clean_BuildID) + '-'+excel_df['Build #'].apply(str).apply(lambda x:x.replace('V','').replace('.0','')).replace('O','')+'-'+excel_df['Test #'].apply(str).apply(lambda x:x.replace('V','').replace('.0',''))
#     excel_df['Test ID'] = excel_df['Sample#'] +'-'+excel_df['Retest'].apply(str).apply(lambda x:x.replace('V','').replace('.0',''))

#     #Austin's spreedsheet
#     Austin_spreadsheet = pd.ExcelFile('/home/aml334/CSE_MSE_RXF131/staging/mds3/fractography/MasterSheet_ULI_Ti6Al4V_Fatigue.xlsx')
#     temp_df = pd.DataFrame()
#     for worksheet in ['Fatigue Test Table','K calculation']:
#         if 'Fatigue Test Table' in worksheet:
#             x = pd.read_excel(Austin_spreadsheet,worksheet,skiprows=1)
#             x['Cycles'] = x['Cycles @ Failure']

#         elif 'K calculation' in  worksheet:
#             x = pd.read_excel(Austin_spreadsheet,worksheet,skiprows=0)
#         if 'ID' in x.columns:
#             x['Sample#'] = x['ID'].apply(m)
#         x = x.loc[:, ~x.columns.str.startswith('Unnamed')]
#         temp_df = pd.concat([temp_df,x])
#     del x

#     excel_df = pd.concat([excel_df,output,temp_df])
#     col = excel_df.pop('Sample#')
#     excel_df.insert(0, 'Sample#', col)
#     #Filter Based on Cycles
#     excel_df = excel_df[excel_df['Cycles'].notna()]
#     excel_df['Ïƒ (Mpa)']= excel_df['Ïƒ max initiation (MPa)']
#     type_counts = excel_df['Cycles'].apply(type).value_counts()

#     print(type_counts)
#     excel_df = excel_df[excel_df['Cycles'].apply(lambda x: isinstance(x, int) or isinstance(x,float))]
#     excel_df['Cycles'] = excel_df['Cycles'].astype(int)
#     type_counts = excel_df['Cycles'].apply(type).value_counts()
#     print(type_counts)

#     del col
#     del output
#     del Austin_spreadsheet
#     del temp_df
#     # In[12]:
#     name = []
#     column_dict = {}
#     i=0
#     column_list = []
#     for column in condition_list:
#         temp_list = []
#         for top_folder in path_list:
#             temp_list.extend(recursive_search(
#                     column,
#                     top_folder,
#                     temp_list
#                 )
#             )
#         name.append((column.__name__,len(temp_list)))
#         column_dict[name[i][0]] = temp_list
#         del temp_list
#         print(str(name[i]) +f'\tPosition: {i}')
#         i+=1

#     # In[17]:
#     # In[17]:
#     check = re.compile(r'''
#         ^
#         (?:x)?
#         (?:\d+)?
#         (?:[a-b])?
#         [-]?
#         (?:Copy\ of\ |Overview|_STD_ETD_|Initiation)?  # Optional prefixes
#         [-]?
#         [\d]?
#         [-]?
#         [x]?
#         (?:\d+)?
#         [-]?
#         (EP|NASA|CMU)                                  # Start with EP, NASA, or CMU (case insensitive)
#         [-_]?                                          # Optional separator
#         (\d+|O\d+)                                     # Number or O followed by number
#         [-_]?                                        # Optional separator
#         V?
#         ([E\d]+|\d+)                                   # Version number
#         [-_]?                                          # Optional separator
#         (\d+)?                                         # Optional additional number
#         (?:_MARKED)?                                   # Optional '_MARKED' suffix
#         (.*)?                                          # Any characters in between (greedy by default)
#         \.(png|tif|tiff|jpg)$                          # File extension
#         ''', re.VERBOSE | re.IGNORECASE)
#     def regex_basename(pattern):
#         match = re.search(check,pattern)
#         if(match):
#             type_func = clean_BuildID(match.group(1)+match.group(2))
#             series_func = match.group(3).lstrip("0")
#             if match.group(4):
#                 posit_idx_func = match.group(4).lstrip("0")
#             else:
#                 posit_idx_func = None
#             return type_func, series_func,posit_idx_func
#         else:
#             return None

#     def exclude(input):
#         conditions = ['.hdr', '.csv','.info','.xlsx','.info','.pptx','.s0001','.zip','.model']
#         for condition in conditions:
#             if condition in input: return True
#         return False

#     def check_regex_basename(dict_to_search,search_function, exclude_conditions):
#         i=0
#         for key in dict_to_search:
#             for field in dict_to_search[key]:
#                 basename = field.split('/')[-1]
#                 if not search_function(basename) and not exclude(basename):
#                     print(basename)
#                     i+=1
#         print('Unselected files: '+str(i))
#         # In[17]:
#     check = re.compile(r'''
#         ^
#         (?:x)?
#         (?:\d+)?
#         (?:[a-b])?
#         [-]?
#         (?:Copy\ of\ |Overview|_STD_ETD_|Initiation)?  # Optional prefixes
#         [-]?
#         [\d]?
#         [-]?
#         [x]?
#         (?:\d+)?
#         [-]?
#         (EP|NASA|CMU)                                  # Start with EP, NASA, or CMU (case insensitive)
#         [-_]?                                          # Optional separator
#         (\d+|O\d+)                                     # Number or O followed by number
#         [-_]?                                        # Optional separator
#         V?
#         ([E\d]+|\d+)                                   # Version number
#         [-_]?                                          # Optional separator
#         (\d+)?                                         # Optional additional number
#         (?:_MARKED)?                                   # Optional '_MARKED' suffix
#         (.*)?                                          # Any characters in between (greedy by default)
#         \.(png|tif|tiff|jpg)$                          # File extension
#         ''', re.VERBOSE | re.IGNORECASE)
#     def regex_basename(pattern):
#         match = re.search(check,pattern)
#         if(match):
#             type_func = clean_BuildID(match.group(1)+match.group(2))
#             series_func = match.group(3).lstrip("0")
#             if match.group(4):
#                 posit_idx_func = match.group(4).lstrip("0")
#             else:
#                 posit_idx_func = None
#             return type_func, series_func,posit_idx_func
#         else:
#             return None

#     def exclude(input):
#         conditions = ['.hdr', '.csv','.info','.xlsx','.info','.pptx','.s0001','.zip','.model']
#         for condition in conditions:
#             if condition in input: return True
#         return False

#     def check_regex_basename(dict_to_search,search_function, exclude_conditions):
#         i=0
#         for key in dict_to_search:
#             for field in dict_to_search[key]:
#                 basename = field.split('/')[-1]
#                 if not search_function(basename) and not exclude(basename):
#                     print(basename)
#                     i+=1
#         print('Unselected files: '+str(i))
#         check_regex_basename(column_dict,regex_basename, exclude)
#     # %%
#     dataframe_list = []
#     for i, key in enumerate(column_dict):
#         type_column = []
#         series_column = []
#         posit_idx_column = []
#         basename = []
#         Sample_num = []
#         path_column = []
#         for j, field in enumerate(column_dict[key]):
#             if regex_basename(field.split('/')[-1]):
#                 path_column.append(field)
#                 type_inst, series_inst, posit_idx_inst = regex_basename(field.split('/')[-1])
#                 type_column.append(type_inst)
#                 series_column.append(series_inst)
#                 posit_idx_column.append(posit_idx_inst)
#                 basename.append(field.split('/')[-1])
#                 if posit_idx_inst == None:
#                     Sample_num.append(type_inst.upper()+'-'+str(series_inst)+'-1')
#                 else:
#                     Sample_num.append(type_inst.upper()+'-'+str(series_inst)+'-'+str(posit_idx_inst))
#         path_column = pd.Series(path_column,name='path')
#         type_column = pd.Series(type_column, name='Build ID')
#         series_column = pd.Series(series_column,name='Build #')
#         posit_idx_column = pd.Series(posit_idx_column,name='Test #')
#         basename_column = pd.Series(basename,name='basename')
#         Sample_num_column= pd.Series(Sample_num, name = 'Sample#')
#         dataframe_list.append(
#             pd.concat(
#                 [
#                     Sample_num_column,
#                     path_column,
#                     type_column,
#                     series_column,
#                     posit_idx_column,
#                     basename_column,
#                 ],
#                 axis=1
#             )
#         )
        

#     if not os.path.exists(csv_dir):
#         os.makedirs(csv_dir)

#     for i, df in enumerate(dataframe_list):
#         unique_samples = df['Sample#'].drop_duplicates()
#         csv_paths = []
#         for sample in unique_samples:
#             print(sample)
#             sample_df = df[df['Sample#'] == sample]
#             print(sample_df)
#             csv_path = csv_dir+f'/{sample}_'+name[i][0]+'.csv'
#             sample_df.to_csv(csv_path, index=False)
#             csv_paths.append(csv_path)
#         sample_column = pd.Series(unique_samples, name="Sample#")
#         path_column = pd.Series(csv_paths, name="path")
#         new_df = pd.concat([sample_column.reset_index(drop=True),path_column.reset_index(drop=True)],axis=1)
#         dataframe_list[i] = new_df

#     # %%
#     combined_df = excel_df[-excel_df['Sample#'].isna()]# all should have a key column
#     for i, dataframe in enumerate(dataframe_list):
#         # print(combined_df['Sample#'])
#         # print(dataframe['Sample#'])
#         # for j in dataframe['path']:
#         #     print(j[-30:])
#         #     pass
#         try:
#             combined_df = pd.merge(combined_df,dataframe,on='Sample#',suffixes=('',f'_{name[i][0]}'),how='outer').sort_values(by='Retest',ascending=False).drop_duplicates('Sample#')
#         except Exception as e:
#             print(e)
#     combined_df.rename(columns={'path':'path_'+name[0][0]},inplace=True)
#     combined_df.to_csv('/mnt/vstor/CSE_MSE_RXF131/lab-staging/mds3/AdvManu/fractography/combined_df.csv')
#     log_message(LOG_FILE,str(len(combined_df))+' :'+MESSAGE)
#     row_structure = '|{:^50}|{:^10}|{:^10}|{:^15}|'
#     print(row_structure.format('Column name', 'Nulls','Values','Position'))
#     i=0
#     for column in combined_df.columns:
#         nas = combined_df[column].isna().sum()
#         print(row_structure.format(column,str(nas),str(len(combined_df[column])-nas),str(i)))
#         log_message(LOG_FILE,str(row_structure.format(column,str(nas),str(len(combined_df[column])-nas),str(i))))
#         i+=1
#     # for m, i in combined_df.iterrows():
#     #     if(isinstance(i['path_overload'],str)):
#     #         print(i['Sample#'])
#     #         print(i['path_overload'])

# else:
#     print(__name__)</code></pre>
</section>
</section>
<section id="training" class="level2">
<h2 class="anchored" data-anchor-id="training">Training</h2>
<p>Next, we need to train the model. Here is an example input.</p>
<p>Most did not learn: <img src="packages/AdvSegLearn/Usage/image8.png" class="img-fluid" alt="Star Guards"></p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>